# -*- coding: utf-8 -*-
"""RESEARCH_Diffusion_Project_Generate_Egyptian_Characters.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t1Azo4PErojk_j9U2Wof3OP-YV55-u9K

#### Links to Download

Egyptian Extended PDF: https://www.unicode.org/charts/PDF/U13460.pdf

NotoSansEgyptianHieroglyphs-Regular Font: https://fonts.google.com/noto/specimen/Noto+Sans+Egyptian+Hieroglyphs

### Step 1: Generate a Egyptian glyph and definition dataset
We can take the kDefinition text file to extract both characters and labels in the form of definitions.

https://github.com/amankiitg/Foundation_AI/blob/de84eb29f8e19b7a66ca8428f38fb818490cfad9/egypt.txt
"""
import re
import zipfile

import pandas as pd
from PIL import Image, ImageDraw, ImageFont

#Initialize lists
unicodes = []
characters = []
descriptions = []
extras = []

file_path = "egypt.txt"
with open(file_path, 'r', encoding='utf-8') as file:
    lines = file.readlines()

i = 0
while i < len(lines):
    line = lines[i].strip()
    if re.match(r'^[0-9A-F]+\s+\S+\s+Egyptian Hieroglyph', line):
        # Main line with code, character, and description
        match = re.match(r'^([0-9A-F]+)\s+(\S+)\s+(Egyptian Hieroglyph .+)', line)
        if match:
            unicode_val = match.group(1)
            char = match.group(2)
            description = match.group(3)

            # Check next line for "•" comment
            extra = ""
            if i + 1 < len(lines) and '•' in lines[i + 1]:
                extra_line = lines[i + 1].strip()
                extra = re.sub(r'^•\s*', '', extra_line)
                i += 1  # Skip extra line

            unicodes.append(unicode_val)
            characters.append(char)
            descriptions.append(description)
            extras.append(extra)
    i += 1

#Create DataFrame
df = pd.DataFrame({
    'Unicode': unicodes,
    'Character': characters,
    'Description': descriptions,
    'Extra': extras
})

df.head()


def count_files(directory_path):
  """Counts the number of files in a given directory.

  Args:
    directory_path: The path to the directory.

  Returns:
    The number of files in the directory.
  """
  if not os.path.isdir(directory_path):
    raise ValueError(f"'{directory_path}' is not a valid directory.")

  file_count = 0
  for item in os.listdir(directory_path):
    item_path = os.path.join(directory_path, item)
    if os.path.isfile(item_path):
      file_count += 1
  return file_count

# Example usage:
directory_path = "data/" # Replace with your directory path

num_files = count_files(directory_path)
print(f"The number of files in '{directory_path}' is: {num_files}")

"""### Step 2: Create the dataset of images

(1) Take a DataFrame df (like the one you previously created from Unihan-kDefinition.txt)

(2) Extract Unicode characters and render them as images using the specified font style (e.g., 128x128 PNGs).

(3) Save them into a directory using their Unicode code points as filenames.
"""


def create_image(character, font, image_size=(128, 128)):
    """
    Create an image of a single Unicode character.
    """
    image = Image.new('RGB', image_size, 'white')
    draw = ImageDraw.Draw(image)
    text_width, text_height = draw.textbbox((0, 0), character, font=font)[2:]
    x = (image_size[0] - text_width) / 2
    y = (image_size[1] - text_height) / 2 - 16
    draw.text((x, y), character, fill='black', font=font)
    return image

def is_character_supported(character, font, image_size=(128, 128)):
    """
    Check if the character is supported by the font.
    """
    image_char = create_image(character, font, image_size)
    image_unknown = create_image("�", font, image_size)  # U+FFFD is the replacement character

    return not image_char.tobytes() == image_unknown.tobytes()

def generate_and_save_images_from_df(df, font_path, column_name="Unicode", directory="data"):
    """
    Generate and save images for each character specified in the DataFrame's column.
    """
    if not os.path.exists(directory):
        os.makedirs(directory)

    font_size = 100
    font = ImageFont.truetype(font_path, font_size)

    for unicode_str in df[column_name]:
        code_point = int(unicode_str, 16)  # Convert hex string to integer
        character = chr(code_point)
        if is_character_supported(character, font):
            img = create_image(character, font)
            filename = os.path.join(directory, f"{code_point:04X}.png")
            img.save(filename)

# Assuming 'df' is your DataFrame and it is already defined and loaded
font_path = 'NotoSansEgyptianHieroglyphs-Regular.ttf'
# Update the function call accordingly
generate_and_save_images_from_df(df, font_path, column_name="Unicode", directory="data")


def count_files(directory_path):
  """Counts the number of files in a given directory.

  Args:
    directory_path: The path to the directory.

  Returns:
    The number of files in the directory.
  """
  if not os.path.isdir(directory_path):
    raise ValueError(f"'{directory_path}' is not a valid directory.")

  file_count = 0
  for item in os.listdir(directory_path):
    item_path = os.path.join(directory_path, item)
    if os.path.isfile(item_path):
      file_count += 1
  return file_count

# Example usage:
directory_path = "data/" # Replace with your directory path

num_files = count_files(directory_path)
print(f"The number of files in '{directory_path}' is: {num_files}")

"""### Step 2b Extract more images from Unicode PDF"""

import fitz  # PyMuPDF


def extract_region_from_pdf(pdf_path, page_number, coords, dpi=300, save_path='output.png'):
    """
    Extract a region from a PDF page as a high-quality image.

    Args:
        pdf_path (str): Path to the PDF file.
        page_number (int): Page number (0-indexed).
        coords (tuple): (x0, y0, x1, y1) in points (1/72 inch).
        dpi (int): Resolution for rendering the PDF.
        save_path (str): Where to save the extracted image.

    Returns:
        PIL.Image.Image: Extracted image region.
    """
    output_dir = 'png_matrix'
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        print(f"Created output directory: {output_dir}")

    # Open the PDF
    doc = fitz.open(pdf_path)
    page = doc.load_page(page_number)

    # Calculate zoom factor from DPI
    zoom = dpi / 72
    mat = fitz.Matrix(zoom, zoom)

    # Render the page to a high-res image
    pix = page.get_pixmap(matrix=mat, alpha=False)

    # Convert to PIL Image
    image = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)

    # Scale coordinates for high DPI
    x0, y0, x1, y1 = [int(c * zoom) for c in coords]

    # Crop and save
    cropped = image.crop((x0, y0, x1, y1))
    cropped.save(output_dir+'/'+str(page_number)+save_path)

    return cropped

region_coords = (68, 93, 512, 726)  # x0, y0, x1, y1 in PDF points (1/72")
for p in range(2,16,2):
  extract_region_from_pdf('egyptian.pdf', p, region_coords, dpi=300, save_path='cropped_image.png')

region_coords = (101, 93, 544, 726)  # x0, y0, x1, y1 in PDF points (1/72")
for p in [1]:
  extract_region_from_pdf('egyptian.pdf', p, region_coords, dpi=300, save_path='cropped_image.png')

region_coords = (100, 93, 544, 726)  # x0, y0, x1, y1 in PDF points (1/72")
for p in range(3,16,2):
  extract_region_from_pdf('egyptian.pdf', p, region_coords, dpi=300, save_path='cropped_image.png')

import pandas as pd


def extract_grid_images(df, i, input_image_path, output_folder, grid_size=(16, 16), trim_px=(1, 1, 1, 0)):
    """
    Extract images from a grid and save them as separate files with boundary trimming.

    Args:
        input_image_path (str): Path to the input image containing the grid
        output_folder (str): Folder where extracted images will be saved
        grid_size (tuple): Number of rows and columns in the grid (rows, cols)
        trim_px (tuple): Pixels to trim from each side (left, top, bottom, right)
    """
    # Create output directory if it doesn't exist
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)
        print(f"Created output directory: {output_folder}")

    # Load the image
    print(f"Loading image from: {input_image_path}")
    img = Image.open(input_image_path)

    # Get image dimensions
    img_width, img_height = img.size

    # Calculate the size of each cell
    cell_width = img_width / grid_size[1]
    cell_height = img_height / grid_size[0]

    # print(f"Image dimensions: {img_width}x{img_height}")
    # print(f"Cell dimensions: {cell_width}x{cell_height}")

    # Extract and save each cell
    total_cells = grid_size[0] * grid_size[1]
    saved_count = 0

    for row in range(grid_size[0]):
        for col in range(grid_size[1]):
            # Calculate coordinates with boundary trimming
            left = col * cell_width + trim_px[0]
            upper = row * cell_height + trim_px[1]
            right = (col + 1) * cell_width - trim_px[3]
            lower = (row + 1) * cell_height - trim_px[2]

            # print((left, upper, right, lower))
            # Crop the cell
            cell = img.crop((left, upper, right, lower))

            # Generate filename with row and column info
            # Using hex codes from the image (13D60 + row*16 + col)
            hex_code = format(0x13D60 + row * 16 + col, 'X')
            filename = str(i)+str(hex_code)+".png"
            df.loc[len(df.index)] = [str(i)+str(hex_code), filename]
            filepath = os.path.join(output_folder, filename)

            # Save the cell
            cell = cell.resize((128, 128), Image.Resampling.LANCZOS)
            cell.save(filepath)
            saved_count += 1

            # Print progress
            # if saved_count % 16 == 0:
            #     print(f"Progress: {saved_count}/{total_cells} images saved")

    print(f"Extraction complete! {saved_count} images saved to {output_folder}")

df = pd.DataFrame(columns=['Unicode','filename'])
# for i in range(1,2):
#   input_image = "png_matrix/"+str(i)+"cropped_image.png"  # Path to your grid image
#   output_folder = "data"#+str(i)  # Output folder name
#   extract_grid_images(df, i, input_image, output_folder, trim_px=(3, 3, 30, 3))

# Full usage
for i in range(1,11):
  input_image = "png_matrix/"+str(i)+"cropped_image.png"  # Path to your grid image
  output_folder = "data"#+str(i)  # Output folder name
  extract_grid_images(df, i, input_image, output_folder, trim_px=(3, 3, 30, 3))

for i in range(11,16):
  input_image = "png_matrix/"+str(i)+"cropped_image.png"  # Path to your grid image
  output_folder = "data"#+str(i)  # Output folder name
  extract_grid_images(df, i, input_image, output_folder, grid_size=(16, 15), trim_px=(3, 3, 30, 3))

num_files = count_files(directory_path)
print(f"The number of files in '{directory_path}' is: {num_files}")

df.head()

"""### Step 3 Rotating Images to Expand Dataset"""

import os
from multiprocessing import Pool, cpu_count

# Configuration
input_folder = "data"
output_folder = os.path.join(input_folder)
os.makedirs(output_folder, exist_ok=True)
angles = range(-25, 26, 5)
extensions = ('.png')

# Function to rotate and crop to original size
def rotate_and_save(args):
    filepath, angle = args
    try:
        with Image.open(filepath) as img:
            img = img.convert("RGBA")
            original_size = img.size
            rotated = img.rotate(angle, resample=Image.BICUBIC, expand=True)
            cropped = rotated.crop((
                (rotated.width - original_size[0]) // 2,
                (rotated.height - original_size[1]) // 2,
                (rotated.width + original_size[0]) // 2,
                (rotated.height + original_size[1]) // 2
            ))
            base_name, ext = os.path.splitext(os.path.basename(filepath))
            save_path = os.path.join(output_folder, f"{base_name}_{angle}deg_rotated{ext}")
            cropped.save(save_path)
    except Exception as e:
        print(f"Error processing {filepath} at {angle} degrees: {e}")

# Prepare tasks
tasks = []
for filename in os.listdir(input_folder):
    if filename.lower().endswith(extensions):
        filepath = os.path.join(input_folder, filename)
        for angle in angles:
            tasks.append((filepath, angle))

# Run in parallel
if __name__ == '__main__':
    with Pool(cpu_count()) as pool:
        pool.map(rotate_and_save, tasks)
    print("All rotations complete.")

num_files = count_files(directory_path)
print(f"The number of files in '{directory_path}' is: {num_files}")